{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAEs_reimplementation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AKJJlIakOrW_"
      ],
      "authorship_tag": "ABX9TyMFHMqSPi0J4cAXy+6qjbsq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaisalAhmed0/variational-autoencoder/blob/main/VAEs_reimplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-26Esxx6hLu"
      },
      "source": [
        "'''\n",
        "This is a reimplementation of the varitional auto encoder based on the original paper \"Auto-Encoding Variational Bayes\". by Kingma et.al\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eunRcP42eN2L"
      },
      "source": [
        "# Imports, Setup, and Data preperation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkjc1owveLAL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as opt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.io import loadmat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj6AgtjAV5II"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH0Gh4zJpGdH"
      },
      "source": [
        "# set the batch size for pytorch data loader\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDTxbGNOflX1"
      },
      "source": [
        "# function to load MNIST dataset\n",
        "def load_mnist(batch_size):\n",
        "  mnist = MNIST(\"./\", train=True, download=True, transform=transforms.Compose([\n",
        "                                                                                transforms.ToTensor()]) )\n",
        "  mnist_test = MNIST(\"./\", train=False, download=True,  transform=transforms.Compose([\n",
        "                                                                              transforms.ToTensor()]) )\n",
        "  mnist_dataloader = DataLoader(mnist, batch_size=batch_size)\n",
        "  mnist_test_dataloader = DataLoader(mnist_test, batch_size=batch_size)\n",
        "  return mnist_dataloader, mnist_test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOPpnStzqQ-f"
      },
      "source": [
        "# function to load frey face dataset\n",
        "def load_frey_face(batch_size):\n",
        "  # download the data\n",
        "  ! wget https://cs.nyu.edu/~roweis/data/frey_rawface.mat\n",
        "\n",
        "  fileName = \"frey_rawface.mat\"\n",
        "  frey_face_mat = loadmat(fileName) # load the mat file\n",
        "  frey_face_input = torch.tensor( frey_face_mat['ff'].T.reshape(-1, 1, 28, 20))\n",
        "  dummy_targets = torch.zeros(frey_face_input.shape[0])\n",
        "  # print(frey_face_input[0])\n",
        "  size = frey_face_input.shape[0]\n",
        "  train_size = int(0.9 * size)\n",
        "\n",
        "  frey_face = TensorDataset((frey_face_input[: train_size]), dummy_targets[: train_size])\n",
        "  frey_face_test = TensorDataset((frey_face_input[train_size: ]), dummy_targets[train_size:])\n",
        "\n",
        "  frey_face_dataloader = DataLoader(frey_face, batch_size=batch_size)\n",
        "  frey_face_test_dataloader = DataLoader(frey_face_test, batch_size=batch_size)\n",
        "  return frey_face_dataloader, frey_face_test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1zafk8jgNin"
      },
      "source": [
        "# plot a batch of images as a grid.\n",
        "def plot_grid(dataloader):\n",
        "  images, _ = next(iter(dataloader))\n",
        "  grid = make_grid(images, )\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.imshow(grid.permute(1, 2, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM4gvoaFjvOs"
      },
      "source": [
        "# load the data\n",
        "mnist, mnist_test = load_mnist(batch_size)\n",
        "freyface, freyface_test = load_frey_face(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr-OMVkfkBwt"
      },
      "source": [
        "# plot a grid of images\n",
        "plot_grid(mnist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByxXSlUwssRC"
      },
      "source": [
        "plot_grid(freyface)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRKVbwOoxC_z"
      },
      "source": [
        "# Model Architecture "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qexu165dtfR_"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  '''\n",
        "  This class defines the encoder architecture\n",
        "  '''\n",
        "  def __init__(self, input_size, hidden_size, bottleneck):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.mean = nn.Linear(hidden_size, bottleneck)\n",
        "    self.var = nn.Linear(hidden_size, bottleneck) \n",
        "\n",
        "    nn.init.normal_(self.linear1.weight, mean=0.0, std=0.01)\n",
        "    nn.init.normal_(self.mean.weight, mean=0.0, std=0.01)\n",
        "    nn.init.normal_(self.var.weight, mean=0.0, std=0.01)\n",
        "    \n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = self.mean(torch.tanh(self.linear1(x)))\n",
        "    log_var =  self.var(torch.tanh(self.linear1(x)))\n",
        "    return mean, log_var"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ISC_BX23PBm"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  '''\n",
        "  This class defines the decoder architecture\n",
        "  '''\n",
        "  def __init__(self, bottleneck, hidden_size, input_size):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(bottleneck, hidden_size)\n",
        "    self.mean = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    nn.init.normal_(self.linear1.weight, mean=0.0, std=0.01)\n",
        "    nn.init.normal_(self.mean.weight, mean=0.0, std=0.01)\n",
        "\n",
        "  def forward(self, x, output_activation=None):\n",
        "    mean = self.mean(torch.tanh(self.linear1(x)))\n",
        "    if output_activation:\n",
        "      return output_activation(mean)\n",
        "    return mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbaTyEl362iZ"
      },
      "source": [
        "# Loss function and Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9maN99E02YIR"
      },
      "source": [
        "def vae_loss(logvar_z, mean_z, output, target, size, batch_size, mse=True):\n",
        "  # KL Divergence between the prior and the posterior\n",
        "  # print(logvar_z.shape)\n",
        "  # print(output.shape)\n",
        "  # print(target.shape)\n",
        "  kl_divergence = - 0.5 * (torch.sum(1 + logvar_z - mean_z.pow(2) - logvar_z.exp(), dim=1)).sum()\n",
        "  # reconstruction loss\n",
        "  if mse:\n",
        "    reconstruction_loss = F.mse_loss(output, target, reduction=\"sum\")\n",
        "  else:\n",
        "    reconstruction_loss = F.binary_cross_entropy(output, target, reduction=\"sum\")\n",
        "  loss = (1/batch_size) * (kl_divergence + reconstruction_loss)\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI5a-hQuF9c1"
      },
      "source": [
        "# simple function to implemenet the reparametrization trick\n",
        "def reparametrization(mean, logv):\n",
        "  eps = torch.randn_like(mean, device=device)\n",
        "  z = mean + eps * logv.exp().pow(0.5)\n",
        "  # print(z.shape)\n",
        "  return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmCCZRTcFysy"
      },
      "source": [
        "def train(encoder, decoder, loss, optimizer, dataloader, epochs, dataset_size, testloader, channels=1, height=28, width=28, plot=True, mse=False,  activation=True, data=\"mnist\", plot_freq=10):\n",
        "  losses = []\n",
        "  test_losses = []\n",
        "  # Main training loop\n",
        "  for epoch in range(epochs):\n",
        "    for img, _ in dataloader:\n",
        "      if data == \"freyface\":\n",
        "        img_flattend = img.reshape(-1, (torch.tensor(img.shape[1:])).prod()).to(torch.float32)\n",
        "      else:\n",
        "        img_flattend = img.reshape(-1, (torch.tensor(img.shape[1:])).prod())\n",
        "      mu, logv = encoder(img_flattend.to(device))\n",
        "      z = reparametrization(mu, logv)\n",
        "      if activation:\n",
        "        output = decoder(z.to(device), torch.sigmoid)\n",
        "      else:\n",
        "        output = decoder(z.to(device))\n",
        "      loss = vae_loss(logv.to(device), mu.to(device), output.to(device), img_flattend.to(device), dataset_size, len(img), mse=mse)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    losses.append(-loss)\n",
        "\n",
        "    # plot some results every 10 epochs\n",
        "    if (epoch+1) % plot_freq == 0 :\n",
        "      targets = img[:10]\n",
        "      output_reshaped = output.reshape(-1, channels, height, width)[:10]\n",
        "      target_grid = make_grid(targets.cpu().detach(), nrow=10)\n",
        "      if mse:\n",
        "        output_grid = make_grid(output_reshaped.cpu().detach().to(torch.int32), nrow=10)\n",
        "      else:\n",
        "        output_grid = make_grid(output_reshaped.cpu().detach(), nrow=10)\n",
        "      if plot:\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.imshow(target_grid.permute(1, 2, 0))\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.imshow(output_grid.permute(1, 2, 0))\n",
        "        plt.show()\n",
        "\n",
        "    # evaluate on the test set\n",
        "    with torch.no_grad():\n",
        "      for img, _ in testloader:\n",
        "        if data == \"freyface\":\n",
        "          img_flattend = img.reshape(-1, (torch.tensor(img.shape[1:])).prod()).to(torch.float32)\n",
        "        else:\n",
        "          img_flattend = img.reshape(-1, (torch.tensor(img.shape[1:])).prod())\n",
        "        mu, logv = encoder(img_flattend.to(device))\n",
        "        z = reparametrization(mu, logv)\n",
        "        if activation:\n",
        "          output = decoder(z.to(device), torch.sigmoid)\n",
        "        else:\n",
        "          output = decoder(z.to(device))\n",
        "        test_loss = vae_loss(logv.to(device), mu.to(device), output.to(device), img_flattend.to(device), dataset_size, len(img), mse=mse)\n",
        "        # test_loss = vae_loss(logv.to(device), mu.to(device), output.to(device), img_flattend.to(device), 60000, len(img), mse=False)\n",
        "      test_losses.append(- test_loss)\n",
        "\n",
        "      print(f\"Epoch: {epoch+1}, train loss: {loss}, test loss: {test_loss}\")\n",
        "\n",
        "  return losses, test_losses,target_grid, output_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKJJlIakOrW_"
      },
      "source": [
        "# Test for the implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8FxJ_gbOYiV"
      },
      "source": [
        "hidden_size = 500\n",
        "bottleneck = 5\n",
        "input_size = 784\n",
        "stepsize = 0.01\n",
        "epochs = 100\n",
        "# add the parameters for weight initlization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSYjOK0SPcMq"
      },
      "source": [
        "encoder = Encoder(input_size, hidden_size, bottleneck).to(device) # define the encoder\n",
        "decoder = Decoder(bottleneck, hidden_size, input_size).to(device) # define the decoder\n",
        "optimizer = opt.Adagrad(list(encoder.parameters()) + list(decoder.parameters()) , lr=stepsize, weight_decay=1) # define the optimizer\n",
        "\n",
        "train(encoder, decoder, vae_loss, optimizer, mnist, epochs, dataset_size=60000, testloader=mnist_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N6RmnCa_VXv"
      },
      "source": [
        "# Experimental Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1S1rGbZDn2U"
      },
      "source": [
        "def experiment(epochs,input_size, hidden_size, bottleneck, height=None, width=None, plot_freq=10):\n",
        "  # save image for comparison\n",
        "  encoder = Encoder(input_size, hidden_size, bottleneck).to(device) # define the encoder\n",
        "  decoder = Decoder(bottleneck, hidden_size, input_size).to(device) # define the decoder\n",
        "\n",
        "  optimizer = opt.Adagrad(list(encoder.parameters()) + list(decoder.parameters()) , lr=stepsize) # define the optimizer\n",
        "  if height != None and width != None:\n",
        "    loss, test_loss, data, output = train(encoder, decoder, vae_loss, optimizer, freyface, epochs, dataset_size=dataset_size, plot=True, testloader=freyface_test, height=height, width=width, data=\"freyface\", mse=True, plot_freq=plot_freq, activation=False)\n",
        "  else:\n",
        "    loss, test_loss, data, output = train(encoder, decoder, vae_loss, optimizer, mnist, epochs, dataset_size=dataset_size, plot=True, testloader=mnist_test, activation=True, mse=False, plot_freq=plot_freq)\n",
        "\n",
        "  return loss, test_loss, data, output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl1iE2slcwoN"
      },
      "source": [
        "def plot_loss(loss, loss_test, n, data=\"MNIST\"):\n",
        "  x_labels = [i*10**6 for i in range(1,len(loss)+1)]\n",
        "  plt.plot(x_labels, loss, '-r', label=\"AEVB (train)\")\n",
        "  plt.plot(x_labels, loss_test, '--r', label=\"AEVB (test)\")\n",
        "  plt.xscale('log')\n",
        "  plt.xlabel(\"# Training samples evaluated\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.savefig(f\"{data} N={n}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB5oFuWD6uLt"
      },
      "source": [
        "# MNIST Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiCpqpkC-SSA"
      },
      "source": [
        "# Experemints setup for MNIST\n",
        "# Networks parameters\n",
        "hidden_size = 500\n",
        "input_size = 784\n",
        "# different size of the latent space\n",
        "N = [3, 5, 10, 20, 200]\n",
        "epochs = 10\n",
        "stepsize = 0.03\n",
        "for bottleneck in N:\n",
        "  loss, test_loss, data, output = experiment(epochs,input_size, hidden_size, bottleneck)\n",
        "  if bottleneck == N[0]:\n",
        "    print(f\"Original images\")\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(data.permute(1, 2, 0))\n",
        "    plt.savefig(\"original_image\")\n",
        "    plt.show()\n",
        "  print(f\"MNIST Image Generated with latent space size of {bottleneck}\")\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  plt.imshow(output.permute(1, 2, 0))\n",
        "  plt.savefig(f\"MNIST Image Generated with latent space size of {bottleneck}\")\n",
        "  plt.show()\n",
        "  print(f\"Losses for N={bottleneck}\")\n",
        "  plot_loss(loss, test_loss, bottleneck)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt9mPCpA9sAo"
      },
      "source": [
        "# Experiments (Frey Face)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyb9vMjEFO6m"
      },
      "source": [
        "# Experemints setup for frey face\n",
        "# Networks parameters\n",
        "hidden_size = 100\n",
        "input_size = 560\n",
        "# different size of the latent space\n",
        "N = [2, 5, 10, 20]\n",
        "epochs =5000\n",
        "dataset_size = 1950\n",
        "stepsize = 0.1\n",
        "for bottleneck in N:\n",
        "  loss, test_loss, data, output = experiment(epochs,input_size, hidden_size, bottleneck, height=28, width=20, plot_freq=100)\n",
        "  if bottleneck == N[0]:\n",
        "    print(f\"Original images fery face\")\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(data.permute(1, 2, 0))\n",
        "    plt.savefig(\"original_image\")\n",
        "    plt.show()\n",
        "  print(f\"frey face Image Generated with latent space size of {bottleneck}\")\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  plt.imshow(output.permute(1, 2, 0))\n",
        "  plt.savefig(f\"frey face Image Generated with latent space size of {bottleneck}\")\n",
        "  plt.show()\n",
        "  print(f\"frey face Losses for N={bottleneck}\")\n",
        "  plot_loss(loss, test_loss, bottleneck,  data=\"Frey face\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}